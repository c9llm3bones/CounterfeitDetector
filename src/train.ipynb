{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399194b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "IMG_H5 = \"../data/image_features.h5\"\n",
    "\n",
    "# Загружаем HDF5\n",
    "with h5py.File(IMG_H5, \"r\") as f:\n",
    "    img_features = f[\"features\"][:]   # (N, D)\n",
    "    img_ids = f[\"ids\"][:]             # (N,)\n",
    "    \n",
    "print(\"Image features shape:\", img_features.shape)\n",
    "print(\"First 5 ids:\", img_ids[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda11e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь {ItemID: индекс в h5}\n",
    "id2idx = {int(i): j for j, i in enumerate(img_ids)}\n",
    "\n",
    "# Матрица для train.csv\n",
    "img_vectors = []\n",
    "for item_id in df[\"ItemID\"]:\n",
    "    if item_id in id2idx:\n",
    "        img_vectors.append(img_features[id2idx[item_id]])\n",
    "    else:\n",
    "        # если вдруг нет картинки → заполним нулями\n",
    "        img_vectors.append(np.zeros(img_features.shape[1]))\n",
    "        \n",
    "img_vectors = np.array(img_vectors)\n",
    "print(\"img_vectors shape:\", img_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa71a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: ['rating_1_count', 'rating_2_count', 'rating_3_count', 'rating_4_count', 'rating_5_count', 'comments_published_count', 'photos_published_count', 'videos_published_count', 'PriceDiscounted', 'item_time_alive', 'item_count_fake_returns7', 'item_count_fake_returns30', 'item_count_fake_returns90', 'item_count_sales7', 'item_count_sales30', 'item_count_sales90', 'item_count_returns7', 'item_count_returns30', 'item_count_returns90', 'GmvTotal7', 'GmvTotal30', 'GmvTotal90', 'ExemplarAcceptedCountTotal7', 'ExemplarAcceptedCountTotal30', 'ExemplarAcceptedCountTotal90', 'OrderAcceptedCountTotal7', 'OrderAcceptedCountTotal30', 'OrderAcceptedCountTotal90', 'ExemplarReturnedCountTotal7', 'ExemplarReturnedCountTotal30', 'ExemplarReturnedCountTotal90', 'ExemplarReturnedValueTotal7', 'ExemplarReturnedValueTotal30', 'ExemplarReturnedValueTotal90', 'ItemVarietyCount', 'ItemAvailableCount', 'seller_time_alive']\n",
      "Cat cols: ['brand_name', 'CommercialTypeName4']\n",
      "Text cols: ['name_rus', 'description']\n",
      "Feature matrix shape: (197198, 80039)\n",
      "[LightGBM] [Info] Number of positive: 10442, number of negative: 147316\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 49.487274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2253640\n",
      "[LightGBM] [Info] Number of data points in the train set: 157758, number of used features: 69812\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 -> best_th=0.660 | val F1=0.8150\n",
      "[LightGBM] [Info] Number of positive: 10441, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 63.912883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2256785\n",
      "[LightGBM] [Info] Number of data points in the train set: 157758, number of used features: 69755\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 -> best_th=0.630 | val F1=0.8247\n",
      "[LightGBM] [Info] Number of positive: 10441, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 48.030056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2255220\n",
      "[LightGBM] [Info] Number of data points in the train set: 157758, number of used features: 69699\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 -> best_th=0.700 | val F1=0.8183\n",
      "[LightGBM] [Info] Number of positive: 10442, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 47.896523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2255345\n",
      "[LightGBM] [Info] Number of data points in the train set: 157759, number of used features: 69590\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 -> best_th=0.760 | val F1=0.8233\n",
      "[LightGBM] [Info] Number of positive: 10442, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 48.365392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2250354\n",
      "[LightGBM] [Info] Number of data points in the train set: 157759, number of used features: 69632\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 -> best_th=0.760 | val F1=0.8236\n",
      "CV folds F1: [0.8150203477617463, 0.8247041420118343, 0.8182861514919664, 0.8233236151603499, 0.823552049259188]\n",
      "OOF F1: 0.820952092177077\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import sparse\n",
    "import lightgbm as lgb\n",
    "\n",
    "TRAIN_CSV = \"../data/ml_ozon_сounterfeit_train.csv\"\n",
    "TEXT_COLS = [\"name_rus\", \"description\"]\n",
    "CAT_COLS = [\"brand_name\", \"CommercialTypeName4\"]   \n",
    "TARGET = \"resolution\"\n",
    "ID_COL = \"id\"   \n",
    "\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "exclude = {ID_COL, \"ItemID\", \"SellerID\", TARGET}\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in exclude]\n",
    "cat_cols = [c for c in CAT_COLS if c in df.columns]\n",
    "\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Cat cols:\", cat_cols)\n",
    "print(\"Text cols:\", [c for c in TEXT_COLS if c in df.columns])\n",
    "\n",
    "for c in cat_cols:\n",
    "    counts = df[c].fillna(\"##NA##\").value_counts(dropna=False).to_dict()\n",
    "    df[c + \"_freq\"] = df[c].fillna(\"##NA##\").map(counts).astype(float)\n",
    "cat_freq_cols = [c + \"_freq\" for c in cat_cols]\n",
    "\n",
    "X_num = df[num_cols].copy()\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_num_imp = imp.fit_transform(X_num)          \n",
    "scaler = StandardScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num_imp)\n",
    "\n",
    "texts = []\n",
    "for i, row in df.iterrows():\n",
    "    pieces = []\n",
    "    for c in TEXT_COLS:\n",
    "        if c in df.columns:\n",
    "            pieces.append(str(row.get(c, \"\")) if pd.notna(row.get(c, \"\")) else \"\")\n",
    "    texts.append(\" \".join(pieces))\n",
    "    \n",
    "tf = TfidfVectorizer(max_features=80_000, ngram_range=(1,2))\n",
    "X_text = tf.fit_transform(texts) \n",
    "\n",
    "if cat_freq_cols:\n",
    "    X_catfreq = df[cat_freq_cols].fillna(0).values\n",
    "else:\n",
    "    X_catfreq = np.zeros((len(df), 0))\n",
    "\n",
    "X_img_sparse = sparse.csr_matrix(img_vectors)\n",
    "\n",
    "X_num_sparse = sparse.csr_matrix(X_num_scaled)\n",
    "X_cat_sparse = sparse.csr_matrix(X_catfreq)\n",
    "\n",
    "# склеиваем всё вместе\n",
    "X = sparse.hstack([X_text, X_cat_sparse, X_num_sparse, X_img_sparse], format=\"csr\")\n",
    "print(\"Final feature matrix shape:\", X_full.shape)\n",
    "\n",
    "y = df[TARGET].values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof = np.zeros(len(df))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced'   # handle imbalance\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric='binary_logloss'\n",
    "    )\n",
    "\n",
    "    pval = clf.predict_proba(X_va)[:,1]\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    best_th, best_f1 = 0.5, 0.0\n",
    "    for t in ths:\n",
    "        f = f1_score(y_va, (pval >= t).astype(int))\n",
    "        if f > best_f1:\n",
    "            best_f1 = f\n",
    "            best_th = t\n",
    "\n",
    "    oof[va_idx] = (pval >= best_th).astype(int)\n",
    "    f1_fold = f1_score(y_va, oof[va_idx])\n",
    "    fold_scores.append(f1_fold)\n",
    "    print(f\"Fold {fold} -> best_th={best_th:.3f} | val F1={f1_fold:.4f}\")\n",
    "\n",
    "print(\"CV folds F1:\", fold_scores)\n",
    "print(\"OOF F1:\", f1_score(y, oof))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4eef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved out/oof_baseline_text_tabular.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Save OOF and vectorizer/scaler for inference ----------\n",
    "df_oof = df[[ID_COL]].copy() if ID_COL in df.columns else df.reset_index()[[\"index\"]].rename(columns={\"index\":\"id\"})\n",
    "df_oof[\"oof_pred\"] = oof.astype(int)\n",
    "df_oof[TARGET] = y\n",
    "df_oof.to_csv(\"../out/oof_baseline_text_tabular.csv\", index=False)\n",
    "print(\"Saved out/oof_baseline_text_tabular.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd61680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test feature matrix shape: (22760, 80039)\n"
     ]
    }
   ],
   "source": [
    "# ---------- LOAD TEST ----------\n",
    "TEST_CSV = \"../data/ml_ozon_сounterfeit_test.csv\"\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# numeric\n",
    "X_num_test = test_df[num_cols].copy()\n",
    "X_num_test_imp = imp.transform(X_num_test)\n",
    "X_num_test_scaled = scaler.transform(X_num_test_imp)\n",
    "X_num_sparse_test = sparse.csr_matrix(X_num_test_scaled)\n",
    "\n",
    "# cat frequency encoding\n",
    "X_catfreq_test = np.zeros((len(test_df), 0))\n",
    "if cat_freq_cols:\n",
    "    for c in cat_cols:\n",
    "        counts = df[c].fillna(\"##NA##\").value_counts(dropna=False).to_dict()\n",
    "        test_df[c + \"_freq\"] = test_df[c].fillna(\"##NA##\").map(counts).astype(float)\n",
    "    X_catfreq_test = test_df[cat_freq_cols].fillna(0).values\n",
    "X_cat_sparse_test = sparse.csr_matrix(X_catfreq_test)\n",
    "\n",
    "# text\n",
    "texts_test = []\n",
    "for i, row in test_df.iterrows():\n",
    "    pieces = []\n",
    "    for c in TEXT_COLS:\n",
    "        if c in test_df.columns:\n",
    "            pieces.append(str(row.get(c, \"\")) if pd.notna(row.get(c, \"\")) else \"\")\n",
    "    texts_test.append(\" \".join(pieces))\n",
    "X_text_test = tf.transform(texts_test)\n",
    "\n",
    "# final sparse matrix\n",
    "X_test = sparse.hstack([X_text_test, X_cat_sparse_test, X_num_sparse_test], format=\"csr\")\n",
    "print(\"Test feature matrix shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ad185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# допустим, models = список моделей по фолдам\n",
    "oof_probs_test = np.zeros(len(test_df))\n",
    "\n",
    "for model in models:\n",
    "    oof_probs_test += model.predict_proba(X_test)[:,1] / len(models)\n",
    "\n",
    "# можно взять средний threshold по фолдам\n",
    "threshold_test = np.mean(best_thresholds)\n",
    "test_preds = (oof_probs_test >= threshold_test).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8341831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10442, number of negative: 147316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 50.529773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2253640\n",
      "[LightGBM] [Info] Number of data points in the train set: 157758, number of used features: 69812\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 -> best_th=0.660 | val F1=0.8150\n",
      "[LightGBM] [Info] Number of positive: 10441, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 48.866597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2256785\n",
      "[LightGBM] [Info] Number of data points in the train set: 157758, number of used features: 69755\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 -> best_th=0.630 | val F1=0.8247\n",
      "[LightGBM] [Info] Number of positive: 10441, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 49.126455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2255220\n",
      "[LightGBM] [Info] Number of data points in the train set: 157758, number of used features: 69699\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 -> best_th=0.700 | val F1=0.8183\n",
      "[LightGBM] [Info] Number of positive: 10442, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 48.632538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2255345\n",
      "[LightGBM] [Info] Number of data points in the train set: 157759, number of used features: 69590\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 -> best_th=0.760 | val F1=0.8233\n",
      "[LightGBM] [Info] Number of positive: 10442, number of negative: 147317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 49.679432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2250354\n",
      "[LightGBM] [Info] Number of data points in the train set: 157759, number of used features: 69632\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 -> best_th=0.760 | val F1=0.8236\n",
      "CV folds F1: [0.8150203477617463, 0.8247041420118343, 0.8182861514919664, 0.8233236151603499, 0.823552049259188]\n",
      "OOF F1: 0.820952092177077\n",
      "Test feature matrix shape: (22760, 80039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using threshold (mean over folds): 0.702\n",
      "Saved submission to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- ADD/REPLACE in your script: keep previous code up to CV setup ----------\n",
    "# (предполагается, что до этого у тебя уже выполнены: df, X, y, tf, imp, scaler, num_cols, cat_cols, cat_freq_cols)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib  # опционально для сохранения моделей на диск\n",
    "import os\n",
    "\n",
    "# CONFIG for inference\n",
    "TEST_CSV = \"../data/ml_ozon_сounterfeit_test.csv\"\n",
    "OUT_SUBMISSION = \"submission.csv\"\n",
    "\n",
    "# Prepare containers\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof = np.zeros(len(df))\n",
    "oof_probs = np.zeros(len(df))\n",
    "models = []             # <-- будем сохранять модели по фолдам\n",
    "best_thresholds = []\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    # fit (можно добавить callbacks=..., verbose=False если нужно)\n",
    "    clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], eval_metric='binary_logloss')\n",
    "\n",
    "    # сохранить модель в список\n",
    "    models.append(clf)\n",
    "\n",
    "    # predict proba on val\n",
    "    pval = clf.predict_proba(X_va)[:,1]\n",
    "    oof_probs[va_idx] = pval\n",
    "\n",
    "    # tune threshold on this val\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    best_th, best_f1 = 0.5, 0.0\n",
    "    for t in ths:\n",
    "        f = f1_score(y_va, (pval >= t).astype(int))\n",
    "        if f > best_f1:\n",
    "            best_f1 = f\n",
    "            best_th = t\n",
    "    best_thresholds.append(best_th)\n",
    "\n",
    "    oof[va_idx] = (pval >= best_th).astype(int)\n",
    "    f1_fold = f1_score(y_va, oof[va_idx])\n",
    "    fold_scores.append(f1_fold)\n",
    "    print(f\"Fold {fold} -> best_th={best_th:.3f} | val F1={f1_fold:.4f}\")\n",
    "\n",
    "print(\"CV folds F1:\", fold_scores)\n",
    "print(\"OOF F1:\", f1_score(y, oof))\n",
    "\n",
    "# (опционально) сохраним модели и трансформеры на диск для повторного использования\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "for i, m in enumerate(models):\n",
    "    joblib.dump(m, f\"models/lgb_fold{i+1}.pkl\")\n",
    "joblib.dump(tf, \"models/tfidf.pkl\")\n",
    "joblib.dump(imp, \"models/imputer.pkl\")\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "# сохраняем мэппинг частот категорий (если понадобится)\n",
    "cat_counts = {c: df[c].fillna(\"##NA##\").value_counts(dropna=False).to_dict() for c in cat_cols}\n",
    "joblib.dump(cat_counts, \"models/cat_counts.pkl\")\n",
    "\n",
    "# ---------- INFERENCE ON TEST ----------\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# prepare numeric part (use same num_cols, imp, scaler)\n",
    "X_num_test = test_df[num_cols].copy()\n",
    "X_num_test_imp = imp.transform(X_num_test)           # imputer fitted on train\n",
    "X_num_test_scaled = scaler.transform(X_num_test_imp)\n",
    "X_num_sparse_test = sparse.csr_matrix(X_num_test_scaled)\n",
    "\n",
    "# prepare cat freq columns (use counts from train: cat_counts)\n",
    "for c in cat_cols:\n",
    "    cnts = cat_counts[c]  # from saved dict\n",
    "    test_df[c + \"_freq\"] = test_df[c].fillna(\"##NA##\").map(cnts).astype(float)\n",
    "X_catfreq_test = test_df[[c + \"_freq\" for c in cat_cols]].fillna(0).values\n",
    "X_cat_sparse_test = sparse.csr_matrix(X_catfreq_test)\n",
    "\n",
    "# prepare text\n",
    "texts_test = []\n",
    "for i, row in test_df.iterrows():\n",
    "    pieces = []\n",
    "    for c in TEXT_COLS:\n",
    "        if c in test_df.columns:\n",
    "            pieces.append(str(row.get(c, \"\")) if pd.notna(row.get(c, \"\")) else \"\")\n",
    "    texts_test.append(\" \".join(pieces))\n",
    "X_text_test = tf.transform(texts_test)   # TF-IDF fitted on train\n",
    "\n",
    "# final test matrix\n",
    "X_test = sparse.hstack([X_text_test, X_cat_sparse_test, X_num_sparse_test], format=\"csr\")\n",
    "print(\"Test feature matrix shape:\", X_test.shape)\n",
    "\n",
    "# predict: average probabilities from CV models\n",
    "probs_test = np.zeros(len(test_df))\n",
    "for m in models:\n",
    "    probs_test += m.predict_proba(X_test)[:,1] / len(models)\n",
    "\n",
    "# threshold to use: average of best_thresholds across folds\n",
    "threshold_test = float(np.mean(best_thresholds))\n",
    "print(\"Using threshold (mean over folds):\", threshold_test)\n",
    "\n",
    "preds_test = (probs_test >= threshold_test).astype(int)\n",
    "\n",
    "# build submission; prefer column ID_COL if exists, else fallback to ItemID or index\n",
    "if ID_COL in test_df.columns:\n",
    "    ids_out = test_df[ID_COL].astype(int)\n",
    "elif \"ItemID\" in test_df.columns:\n",
    "    ids_out = test_df[\"ItemID\"].astype(int)\n",
    "else:\n",
    "    ids_out = test_df.index.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\"id\": ids_out, \"prediction\": preds_test})\n",
    "submission.to_csv(OUT_SUBMISSION, index=False)\n",
    "print(\"Saved submission to\", OUT_SUBMISSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f19d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
